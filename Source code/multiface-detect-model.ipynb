{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":7343023,"sourceType":"datasetVersion","datasetId":4263653},{"sourceId":7358929,"sourceType":"datasetVersion","datasetId":4274332},{"sourceId":7380886,"sourceType":"datasetVersion","datasetId":4289379},{"sourceId":7380982,"sourceType":"datasetVersion","datasetId":4289440},{"sourceId":7381202,"sourceType":"datasetVersion","datasetId":4289582}],"dockerImageVersionId":30627,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# For tips on running notebooks in Google Colab, see\n# https://pytorch.org/tutorials/beginner/colab\n%matplotlib inline\n!pip install torchvision==0.16\n!pip install pycocotools","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2024-01-15T14:24:35.829748Z","iopub.execute_input":"2024-01-15T14:24:35.830136Z","iopub.status.idle":"2024-01-15T14:27:59.458109Z","shell.execute_reply.started":"2024-01-15T14:24:35.830106Z","shell.execute_reply":"2024-01-15T14:27:59.456025Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Import các thư viện cần thiết","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nfrom torchvision.io import read_image\nimport pandas as pd\nimport os\nimport torch\n\nfrom torchvision.io import read_image\nfrom torchvision import tv_tensors\nfrom torchvision.transforms.v2 import functional as F\nfrom torchvision.transforms import v2 as T\nimport ast\nimport torchvision\nfrom torchvision.models.detection.faster_rcnn import FastRCNNPredictor\nfrom torchvision.models.detection.rpn import AnchorGenerator\nfrom torchvision.models.detection import FasterRCNN\nimport torch.nn as nn\nimport utils\nfrom engine import train_one_epoch, evaluate","metadata":{"execution":{"iopub.status.busy":"2024-01-15T14:27:59.46208Z","iopub.execute_input":"2024-01-15T14:27:59.462507Z","iopub.status.idle":"2024-01-15T14:28:05.893798Z","shell.execute_reply.started":"2024-01-15T14:27:59.462472Z","shell.execute_reply":"2024-01-15T14:28:05.892477Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"os.system(\"wget https://raw.githubusercontent.com/pytorch/vision/main/references/detection/engine.py\")\nos.system(\"wget https://raw.githubusercontent.com/pytorch/vision/main/references/detection/utils.py\")\nos.system(\"wget https://raw.githubusercontent.com/pytorch/vision/main/references/detection/coco_utils.py\")\nos.system(\"wget https://raw.githubusercontent.com/pytorch/vision/main/references/detection/coco_eval.py\")\nos.system(\"wget https://raw.githubusercontent.com/pytorch/vision/main/references/detection/transforms.py\")","metadata":{"execution":{"iopub.status.busy":"2024-01-15T14:28:05.895619Z","iopub.execute_input":"2024-01-15T14:28:05.896352Z","iopub.status.idle":"2024-01-15T14:28:08.010151Z","shell.execute_reply.started":"2024-01-15T14:28:05.896313Z","shell.execute_reply":"2024-01-15T14:28:08.008855Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Xem qua ảnh trong bộ dataset","metadata":{}},{"cell_type":"code","source":"image = read_image(\"/kaggle/input/face-recognition/mnt/md0/projects/sami-hackathon/private/data/47540406.jpg\")\n\nplt.figure(figsize=(16, 8))\nplt.subplot(121)\nplt.title(\"Image\")\nplt.imshow(image.permute(1, 2, 0))","metadata":{"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-01-15T14:28:08.043469Z","iopub.execute_input":"2024-01-15T14:28:08.044525Z","iopub.status.idle":"2024-01-15T14:28:09.513411Z","shell.execute_reply.started":"2024-01-15T14:28:08.044477Z","shell.execute_reply":"2024-01-15T14:28:09.512376Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/labels/labels.csv\")\nprint((df['file_name'].value_counts()))","metadata":{"execution":{"iopub.status.busy":"2024-01-11T06:26:11.501914Z","iopub.execute_input":"2024-01-11T06:26:11.502205Z","iopub.status.idle":"2024-01-11T06:26:11.598358Z","shell.execute_reply.started":"2024-01-11T06:26:11.502179Z","shell.execute_reply":"2024-01-11T06:26:11.597456Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Dataset for FaceAnalysis","metadata":{}},{"cell_type":"code","source":"class FaceDetectDataset(torch.utils.data.Dataset):\n    def __init__(self, label_root, data_root, transforms):\n        self.label_root = label_root\n        self.data_root = data_root\n        self.transforms = transforms\n        # load all image files, sorting them to\n        # ensure that they are aligned\n        self.df = pd.read_csv(\n            os.path.join(self.label_root, \"labels.csv\"),\n            converters={'bbox': ast.literal_eval}\n        )\n        self.imgs = list(self.df['file_name'])\n        self.img_counts = self.df['file_name'].value_counts()\n\n    def __getitem__(self, idx):\n        # load images and masks\n        img_path = os.path.join(self.data_root, self.imgs[idx])\n        img = read_image(img_path)\n\n        num_objs = self.img_counts[self.imgs[idx]]\n\n        # get bounding box coordinates for each mask\n        boxes = []\n        for i in range(len(self.df)):\n            if self.df.loc[i,'file_name'] == self.imgs[idx]:\n                tmp = self.df.loc[i, 'bbox']\n                boxes.append([tmp[0],tmp[1], tmp[0] + tmp[2], tmp[1] + tmp[3]])\n\n        boxes = torch.tensor(boxes, dtype=torch.float32)\n        # there is only one class\n        labels = torch.ones((num_objs,), dtype=torch.int64)\n\n        image_id = idx\n        area = (boxes[:, 3] - boxes[:, 1]) * (boxes[:, 2] - boxes[:, 0])\n        # suppose all instances are not crowd\n        iscrowd = torch.zeros((num_objs,), dtype=torch.int64)\n\n        # Wrap sample and targets into torchvision tv_tensors:\n        img = tv_tensors.Image(img)\n\n        target = {}\n        target[\"boxes\"] = tv_tensors.BoundingBoxes(boxes, format=\"XYXY\", canvas_size=F.get_size(img))\n        target[\"labels\"] = labels\n        target[\"image_id\"] = image_id\n        target[\"area\"] = area\n        target[\"iscrowd\"] = iscrowd\n\n        if self.transforms is not None:\n            img, target = self.transforms(img, target)\n\n        return img, target\n\n    def __len__(self):\n        return len(self.imgs)","metadata":{"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-01-11T06:26:11.599651Z","iopub.execute_input":"2024-01-11T06:26:11.60003Z","iopub.status.idle":"2024-01-11T06:26:11.614184Z","shell.execute_reply.started":"2024-01-11T06:26:11.599995Z","shell.execute_reply":"2024-01-11T06:26:11.613242Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Hàm sử dụng để transform ảnh và tạo model","metadata":{}},{"cell_type":"code","source":"def get_transform(train):\n    transforms = []\n    if train:\n        transforms.append(T.RandomHorizontalFlip(0.5))\n    transforms.append(T.ToDtype(torch.float, scale=True))\n    transforms.append(T.ToPureTensor())\n    return T.Compose(transforms)\n\ndef get_model(num_classes):\n    # Load pre-trained Faster R-CNN model\n    model = torchvision.models.detection.fasterrcnn_resnet50_fpn(weights=\"DEFAULT\")\n\n    # Modify the last fully connected layer of the classifier\n    in_features = model.roi_heads.box_predictor.cls_score.in_features\n    # replace the pre-trained head with a new one\n    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n    \n    return model","metadata":{"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-01-11T06:26:11.615411Z","iopub.execute_input":"2024-01-11T06:26:11.615677Z","iopub.status.idle":"2024-01-11T06:26:11.62813Z","shell.execute_reply.started":"2024-01-11T06:26:11.615653Z","shell.execute_reply":"2024-01-11T06:26:11.627326Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Test thử model","metadata":{}},{"cell_type":"code","source":"model = get_model(num_classes= 2)\ndataset = FaceDetectDataset(data_root='/kaggle/input/face-recognition/mnt/md0/projects/sami-hackathon/private/data',\n                            label_root='/kaggle/input/labels',\n                            transforms= get_transform(train=True))\ndata_loader = torch.utils.data.DataLoader(\n    dataset,\n    batch_size=4,\n    shuffle=True,\n    num_workers=4,\n    collate_fn=utils.collate_fn\n)\n\nimages, targets = next(iter(data_loader))\nimages = list(image for image in images)\ntargets = [{k: v for k, v in t.items()} for t in targets]\noutput = model(images, targets)  # Returns losses and detections\nprint(output)\n\n# For inference\nmodel.eval()\nx = [torch.rand(3, 300, 400), torch.rand(3, 500, 400)]\npredictions = model(x)  # Returns predictions\nprint(predictions[0])","metadata":{"execution":{"iopub.status.busy":"2024-01-11T02:09:42.027507Z","iopub.execute_input":"2024-01-11T02:09:42.028353Z","iopub.status.idle":"2024-01-11T02:10:37.239779Z","shell.execute_reply.started":"2024-01-11T02:09:42.028315Z","shell.execute_reply":"2024-01-11T02:10:37.238635Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Train model","metadata":{}},{"cell_type":"code","source":"# train on the GPU or on the CPU, if a GPU is not available\ndevice = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n\n# our dataset has two classes only - background and person\nnum_classes = 2\n# use our dataset and defined transformations\ndataset = FaceDetectDataset(data_root='/kaggle/input/face-recognition/mnt/md0/projects/sami-hackathon/private/data',\n                            label_root='/kaggle/input/labels',\n                            transforms= get_transform(train=True))\ndataset_test = FaceDetectDataset(data_root='/kaggle/input/face-recognition/mnt/md0/projects/sami-hackathon/private/data',\n                            label_root='/kaggle/input/labels',\n                            transforms= get_transform(train=False))\n\n# split the dataset in train and test set\nindices = torch.randperm(len(dataset)).tolist()\ndataset = torch.utils.data.Subset(dataset, indices[:-50])\ndataset_test = torch.utils.data.Subset(dataset_test, indices[-50:])\n\n# define training and validation data loaders\ndata_loader = torch.utils.data.DataLoader(\n    dataset,\n    batch_size=4,\n    shuffle=True,\n    num_workers=4,\n    collate_fn=utils.collate_fn\n)\n\ndata_loader_test = torch.utils.data.DataLoader(\n    dataset_test,\n    batch_size=1,\n    shuffle=False,\n    num_workers=4,\n    collate_fn=utils.collate_fn\n)\n\n# get the model using our helper function\nmodel = get_model(num_classes)\n# model= nn.DataParallel(model)\n# move model to the right device\nmodel.to(device)\n\nmodel.load_state_dict(torch.load(\"/kaggle/input/modelweights/model.pth\"))\n\n# construct an optimizer\nparams = [p for p in model.parameters() if p.requires_grad]\noptimizer = torch.optim.SGD(\n    params,\n    lr=0.005,\n    momentum=0.9,\n    weight_decay=0.0005\n)\n\n# and a learning rate scheduler\nlr_scheduler = torch.optim.lr_scheduler.StepLR(\n    optimizer,\n    step_size=3,\n    gamma=0.1\n)\n\n# let's train it just for 2 epochs\nnum_epochs = 2\n\nfor epoch in range(num_epochs):\n    # train for one epoch, printing every 100 iterations\n    train_one_epoch(model, optimizer, data_loader, device, epoch, print_freq=100)\n    # update the learning rate\n    lr_scheduler.step()\n    # evaluate on the test dataset\n    evaluate(model, data_loader_test, device=device)\n\nprint(\"That's it!\")","metadata":{"execution":{"iopub.status.busy":"2024-01-11T02:10:37.242461Z","iopub.execute_input":"2024-01-11T02:10:37.24289Z","iopub.status.idle":"2024-01-11T04:08:06.691835Z","shell.execute_reply.started":"2024-01-11T02:10:37.24285Z","shell.execute_reply":"2024-01-11T04:08:06.689739Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Lưu lại weights của model","metadata":{}},{"cell_type":"code","source":"torch.save(model.state_dict(), \"model_v2.pth\")","metadata":{"execution":{"iopub.status.busy":"2024-01-11T04:09:43.354216Z","iopub.execute_input":"2024-01-11T04:09:43.35497Z","iopub.status.idle":"2024-01-11T04:09:43.638317Z","shell.execute_reply.started":"2024-01-11T04:09:43.354936Z","shell.execute_reply":"2024-01-11T04:09:43.637311Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Epochs","metadata":{}},{"cell_type":"code","source":"# Epoch: [0]  [   0/3815]  eta: 4:36:36  lr: 0.000010  loss: 0.5750 (0.5750)  loss_classifier: 0.4692 (0.4692)  loss_box_reg: 0.0623 (0.0623)  loss_objectness: 0.0331 (0.0331)  loss_rpn_box_reg: 0.0105 (0.0105)  time: 4.3504  data: 3.0938  max mem: 12776\n# Epoch: [0]  [ 100/3815]  eta: 1:33:05  lr: 0.000509  loss: 0.2066 (0.2898)  loss_classifier: 0.0835 (0.1500)  loss_box_reg: 0.1089 (0.0929)  loss_objectness: 0.0057 (0.0395)  loss_rpn_box_reg: 0.0046 (0.0074)  time: 1.4545  data: 0.0383  max mem: 12776\n# Epoch: [0]  [ 200/3815]  eta: 1:29:41  lr: 0.001009  loss: 0.1267 (0.2307)  loss_classifier: 0.0380 (0.1039)  loss_box_reg: 0.0869 (0.0984)  loss_objectness: 0.0029 (0.0230)  loss_rpn_box_reg: 0.0022 (0.0054)  time: 1.5065  data: 0.0382  max mem: 12776\n# Epoch: [0]  [ 300/3815]  eta: 1:27:18  lr: 0.001508  loss: 0.0768 (0.1941)  loss_classifier: 0.0234 (0.0817)  loss_box_reg: 0.0535 (0.0913)  loss_objectness: 0.0003 (0.0164)  loss_rpn_box_reg: 0.0014 (0.0047)  time: 1.4689  data: 0.0370  max mem: 12776\n# Epoch: [0]  [ 400/3815]  eta: 1:24:22  lr: 0.002008  loss: 0.0787 (0.1717)  loss_classifier: 0.0248 (0.0687)  loss_box_reg: 0.0525 (0.0859)  loss_objectness: 0.0004 (0.0130)  loss_rpn_box_reg: 0.0010 (0.0041)  time: 1.4734  data: 0.0363  max mem: 12776\n# Epoch: [0]  [ 500/3815]  eta: 1:21:39  lr: 0.002507  loss: 0.0714 (0.1546)  loss_classifier: 0.0224 (0.0603)  loss_box_reg: 0.0479 (0.0801)  loss_objectness: 0.0001 (0.0106)  loss_rpn_box_reg: 0.0010 (0.0035)  time: 1.5449  data: 0.0376  max mem: 12776\n# Epoch: [0]  [ 600/3815]  eta: 1:19:19  lr: 0.003007  loss: 0.0640 (0.1422)  loss_classifier: 0.0205 (0.0545)  loss_box_reg: 0.0457 (0.0754)  loss_objectness: 0.0001 (0.0090)  loss_rpn_box_reg: 0.0008 (0.0032)  time: 1.5345  data: 0.0353  max mem: 12776\n# Epoch: [0]  [ 700/3815]  eta: 1:17:01  lr: 0.003506  loss: 0.0601 (0.1317)  loss_classifier: 0.0176 (0.0497)  loss_box_reg: 0.0398 (0.0713)  loss_objectness: 0.0001 (0.0079)  loss_rpn_box_reg: 0.0008 (0.0029)  time: 1.4229  data: 0.0391  max mem: 12776\n# Epoch: [0]  [ 800/3815]  eta: 1:14:44  lr: 0.004006  loss: 0.0590 (0.1249)  loss_classifier: 0.0178 (0.0463)  loss_box_reg: 0.0384 (0.0689)  loss_objectness: 0.0001 (0.0070)  loss_rpn_box_reg: 0.0008 (0.0027)  time: 1.4270  data: 0.0375  max mem: 12776\n# Epoch: [0]  [ 900/3815]  eta: 1:12:32  lr: 0.004505  loss: 0.0640 (0.1187)  loss_classifier: 0.0184 (0.0435)  loss_box_reg: 0.0446 (0.0665)  loss_objectness: 0.0002 (0.0063)  loss_rpn_box_reg: 0.0008 (0.0025)  time: 1.5618  data: 0.0363  max mem: 12776\n# Epoch: [0]  [1000/3815]  eta: 1:10:12  lr: 0.005000  loss: 0.0550 (0.1126)  loss_classifier: 0.0184 (0.0410)  loss_box_reg: 0.0331 (0.0636)  loss_objectness: 0.0001 (0.0057)  loss_rpn_box_reg: 0.0006 (0.0023)  time: 1.6032  data: 0.0373  max mem: 12776\n# Epoch: [0]  [1100/3815]  eta: 1:07:39  lr: 0.005000  loss: 0.0517 (0.1079)  loss_classifier: 0.0139 (0.0389)  loss_box_reg: 0.0370 (0.0615)  loss_objectness: 0.0000 (0.0052)  loss_rpn_box_reg: 0.0005 (0.0022)  time: 1.4623  data: 0.0382  max mem: 12776\n# Epoch: [0]  [1200/3815]  eta: 1:05:09  lr: 0.005000  loss: 0.0571 (0.1035)  loss_classifier: 0.0158 (0.0370)  loss_box_reg: 0.0387 (0.0595)  loss_objectness: 0.0002 (0.0049)  loss_rpn_box_reg: 0.0007 (0.0021)  time: 1.5879  data: 0.0379  max mem: 12776\n# Epoch: [0]  [1300/3815]  eta: 1:02:40  lr: 0.005000  loss: 0.0463 (0.0997)  loss_classifier: 0.0142 (0.0354)  loss_box_reg: 0.0290 (0.0577)  loss_objectness: 0.0001 (0.0046)  loss_rpn_box_reg: 0.0006 (0.0020)  time: 1.4295  data: 0.0369  max mem: 12776\n# Epoch: [0]  [1400/3815]  eta: 1:00:07  lr: 0.005000  loss: 0.0458 (0.0968)  loss_classifier: 0.0147 (0.0342)  loss_box_reg: 0.0311 (0.0564)  loss_objectness: 0.0002 (0.0043)  loss_rpn_box_reg: 0.0005 (0.0019)  time: 1.4136  data: 0.0395  max mem: 12776\n# Epoch: [0]  [1500/3815]  eta: 0:57:30  lr: 0.005000  loss: 0.0533 (0.0942)  loss_classifier: 0.0150 (0.0331)  loss_box_reg: 0.0357 (0.0552)  loss_objectness: 0.0002 (0.0041)  loss_rpn_box_reg: 0.0007 (0.0019)  time: 1.3769  data: 0.0372  max mem: 12776\n# Epoch: [0]  [1600/3815]  eta: 0:55:04  lr: 0.005000  loss: 0.0395 (0.0913)  loss_classifier: 0.0099 (0.0319)  loss_box_reg: 0.0268 (0.0538)  loss_objectness: 0.0001 (0.0038)  loss_rpn_box_reg: 0.0004 (0.0018)  time: 1.5360  data: 0.0365  max mem: 12776\n# Epoch: [0]  [1700/3815]  eta: 0:52:35  lr: 0.005000  loss: 0.0391 (0.0890)  loss_classifier: 0.0112 (0.0310)  loss_box_reg: 0.0272 (0.0527)  loss_objectness: 0.0001 (0.0036)  loss_rpn_box_reg: 0.0005 (0.0017)  time: 1.5256  data: 0.0374  max mem: 12776\n# Epoch: [0]  [1800/3815]  eta: 0:50:04  lr: 0.005000  loss: 0.0426 (0.0869)  loss_classifier: 0.0129 (0.0301)  loss_box_reg: 0.0314 (0.0517)  loss_objectness: 0.0003 (0.0035)  loss_rpn_box_reg: 0.0005 (0.0017)  time: 1.4562  data: 0.0373  max mem: 12776\n# Epoch: [0]  [1900/3815]  eta: 0:47:33  lr: 0.005000  loss: 0.0390 (0.0849)  loss_classifier: 0.0116 (0.0293)  loss_box_reg: 0.0283 (0.0507)  loss_objectness: 0.0001 (0.0033)  loss_rpn_box_reg: 0.0004 (0.0016)  time: 1.5403  data: 0.0386  max mem: 12776\n# Epoch: [0]  [2000/3815]  eta: 0:45:05  lr: 0.005000  loss: 0.0368 (0.0832)  loss_classifier: 0.0119 (0.0286)  loss_box_reg: 0.0253 (0.0499)  loss_objectness: 0.0001 (0.0032)  loss_rpn_box_reg: 0.0005 (0.0016)  time: 1.4208  data: 0.0372  max mem: 12776\n# Epoch: [0]  [2100/3815]  eta: 0:42:32  lr: 0.005000  loss: 0.0387 (0.0815)  loss_classifier: 0.0130 (0.0279)  loss_box_reg: 0.0263 (0.0490)  loss_objectness: 0.0001 (0.0030)  loss_rpn_box_reg: 0.0005 (0.0015)  time: 1.3692  data: 0.0374  max mem: 12776\n# Epoch: [0]  [2200/3815]  eta: 0:40:03  lr: 0.005000  loss: 0.0366 (0.0798)  loss_classifier: 0.0121 (0.0272)  loss_box_reg: 0.0256 (0.0482)  loss_objectness: 0.0001 (0.0029)  loss_rpn_box_reg: 0.0005 (0.0015)  time: 1.5452  data: 0.0376  max mem: 12776\n# Epoch: [0]  [2300/3815]  eta: 0:37:32  lr: 0.005000  loss: 0.0330 (0.0783)  loss_classifier: 0.0111 (0.0267)  loss_box_reg: 0.0217 (0.0473)  loss_objectness: 0.0002 (0.0028)  loss_rpn_box_reg: 0.0003 (0.0015)  time: 1.5216  data: 0.0373  max mem: 12776\n# Epoch: [0]  [2400/3815]  eta: 0:35:02  lr: 0.005000  loss: 0.0405 (0.0772)  loss_classifier: 0.0122 (0.0263)  loss_box_reg: 0.0270 (0.0467)  loss_objectness: 0.0001 (0.0027)  loss_rpn_box_reg: 0.0004 (0.0014)  time: 1.5120  data: 0.0384  max mem: 12776\n# Epoch: [0]  [2500/3815]  eta: 0:32:35  lr: 0.005000  loss: 0.0332 (0.0759)  loss_classifier: 0.0094 (0.0258)  loss_box_reg: 0.0244 (0.0460)  loss_objectness: 0.0001 (0.0026)  loss_rpn_box_reg: 0.0003 (0.0014)  time: 1.5113  data: 0.0360  max mem: 12776\n# Epoch: [0]  [2600/3815]  eta: 0:30:07  lr: 0.005000  loss: 0.0319 (0.0746)  loss_classifier: 0.0109 (0.0253)  loss_box_reg: 0.0205 (0.0454)  loss_objectness: 0.0001 (0.0026)  loss_rpn_box_reg: 0.0003 (0.0014)  time: 1.4930  data: 0.0365  max mem: 12776\n# Epoch: [0]  [2700/3815]  eta: 0:27:39  lr: 0.005000  loss: 0.0371 (0.0735)  loss_classifier: 0.0109 (0.0249)  loss_box_reg: 0.0266 (0.0448)  loss_objectness: 0.0001 (0.0025)  loss_rpn_box_reg: 0.0005 (0.0013)  time: 1.4832  data: 0.0366  max mem: 12776\n# Epoch: [0]  [2800/3815]  eta: 0:25:11  lr: 0.005000  loss: 0.0340 (0.0724)  loss_classifier: 0.0113 (0.0245)  loss_box_reg: 0.0226 (0.0442)  loss_objectness: 0.0001 (0.0024)  loss_rpn_box_reg: 0.0005 (0.0013)  time: 1.5101  data: 0.0380  max mem: 12776\n# Epoch: [0]  [2900/3815]  eta: 0:22:41  lr: 0.005000  loss: 0.0369 (0.0715)  loss_classifier: 0.0108 (0.0241)  loss_box_reg: 0.0232 (0.0437)  loss_objectness: 0.0001 (0.0023)  loss_rpn_box_reg: 0.0004 (0.0013)  time: 1.4242  data: 0.0358  max mem: 12776\n# Epoch: [0]  [3000/3815]  eta: 0:20:11  lr: 0.005000  loss: 0.0376 (0.0705)  loss_classifier: 0.0104 (0.0237)  loss_box_reg: 0.0261 (0.0432)  loss_objectness: 0.0001 (0.0023)  loss_rpn_box_reg: 0.0005 (0.0013)  time: 1.4944  data: 0.0354  max mem: 12776\n# Epoch: [0]  [3100/3815]  eta: 0:17:43  lr: 0.005000  loss: 0.0345 (0.0697)  loss_classifier: 0.0110 (0.0234)  loss_box_reg: 0.0238 (0.0428)  loss_objectness: 0.0001 (0.0022)  loss_rpn_box_reg: 0.0003 (0.0013)  time: 1.5090  data: 0.0366  max mem: 12776\n# Epoch: [0]  [3200/3815]  eta: 0:15:14  lr: 0.005000  loss: 0.0366 (0.0688)  loss_classifier: 0.0104 (0.0231)  loss_box_reg: 0.0224 (0.0423)  loss_objectness: 0.0000 (0.0022)  loss_rpn_box_reg: 0.0003 (0.0012)  time: 1.5429  data: 0.0380  max mem: 12776\n# Epoch: [0]  [3300/3815]  eta: 0:12:45  lr: 0.005000  loss: 0.0365 (0.0680)  loss_classifier: 0.0103 (0.0227)  loss_box_reg: 0.0247 (0.0419)  loss_objectness: 0.0001 (0.0021)  loss_rpn_box_reg: 0.0005 (0.0012)  time: 1.4599  data: 0.0388  max mem: 12776\n# Epoch: [0]  [3400/3815]  eta: 0:10:16  lr: 0.005000  loss: 0.0332 (0.0672)  loss_classifier: 0.0089 (0.0225)  loss_box_reg: 0.0228 (0.0415)  loss_objectness: 0.0001 (0.0021)  loss_rpn_box_reg: 0.0004 (0.0012)  time: 1.5232  data: 0.0372  max mem: 12776\n# Epoch: [0]  [3500/3815]  eta: 0:07:48  lr: 0.005000  loss: 0.0370 (0.0665)  loss_classifier: 0.0110 (0.0222)  loss_box_reg: 0.0255 (0.0411)  loss_objectness: 0.0001 (0.0020)  loss_rpn_box_reg: 0.0004 (0.0012)  time: 1.5947  data: 0.0373  max mem: 12776\n# Epoch: [0]  [3600/3815]  eta: 0:05:19  lr: 0.005000  loss: 0.0369 (0.0657)  loss_classifier: 0.0124 (0.0219)  loss_box_reg: 0.0214 (0.0407)  loss_objectness: 0.0001 (0.0020)  loss_rpn_box_reg: 0.0003 (0.0012)  time: 1.4863  data: 0.0362  max mem: 12776\n# Epoch: [0]  [3700/3815]  eta: 0:02:50  lr: 0.005000  loss: 0.0375 (0.0650)  loss_classifier: 0.0111 (0.0216)  loss_box_reg: 0.0237 (0.0403)  loss_objectness: 0.0001 (0.0019)  loss_rpn_box_reg: 0.0005 (0.0011)  time: 1.5034  data: 0.0389  max mem: 12776\n# Epoch: [0]  [3800/3815]  eta: 0:00:22  lr: 0.005000  loss: 0.0380 (0.0643)  loss_classifier: 0.0103 (0.0214)  loss_box_reg: 0.0250 (0.0399)  loss_objectness: 0.0001 (0.0019)  loss_rpn_box_reg: 0.0004 (0.0011)  time: 1.4792  data: 0.0370  max mem: 12776\n# Epoch: [0]  [3814/3815]  eta: 0:00:01  lr: 0.005000  loss: 0.0345 (0.0642)  loss_classifier: 0.0115 (0.0214)  loss_box_reg: 0.0240 (0.0398)  loss_objectness: 0.0002 (0.0019)  loss_rpn_box_reg: 0.0004 (0.0011)  time: 1.4308  data: 0.0350  max mem: 12776\n# Epoch: [0] Total time: 1:34:25 (1.4850 s / it)\n# creating index...\n# index created!\n# Test:  [ 0/50]  eta: 0:01:15  model_time: 0.5408 (0.5408)  evaluator_time: 0.0304 (0.0304)  time: 1.5029  data: 0.9208  max mem: 12776\n# Test:  [49/50]  eta: 0:00:00  model_time: 0.1157 (0.1473)  evaluator_time: 0.0063 (0.0085)  time: 0.1627  data: 0.0124  max mem: 12776\n# Test: Total time: 0:00:10 (0.2019 s / it)\n# Averaged stats: model_time: 0.1157 (0.1473)  evaluator_time: 0.0063 (0.0085)\n# Accumulating evaluation results...\n# DONE (t=0.02s).\n# IoU metric: bbox\n#  Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.846\n#  Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 1.000\n#  Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.965\n#  Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n#  Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.664\n#  Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.867\n#  Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.620\n#  Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.789\n#  Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.863\n#  Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n#  Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.671\n#  Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.884","metadata":{"jupyter":{"source_hidden":true}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Epoch: [0]  [   0/3815]  eta: 5:40:04  lr: 0.000010  loss: 0.0482 (0.0482)  loss_classifier: 0.0128 (0.0128)  loss_box_reg: 0.0320 (0.0320)  loss_objectness: 0.0028 (0.0028)  loss_rpn_box_reg: 0.0005 (0.0005)  time: 5.3485  data: 2.3902  max mem: 4980\n# Epoch: [0]  [ 100/3815]  eta: 0:52:30  lr: 0.000509  loss: 0.0299 (0.0363)  loss_classifier: 0.0094 (0.0120)  loss_box_reg: 0.0180 (0.0234)  loss_objectness: 0.0001 (0.0003)  loss_rpn_box_reg: 0.0003 (0.0005)  time: 0.8295  data: 0.0361  max mem: 7566\n# Epoch: [0]  [ 200/3815]  eta: 0:49:31  lr: 0.001009  loss: 0.0304 (0.0345)  loss_classifier: 0.0093 (0.0112)  loss_box_reg: 0.0219 (0.0226)  loss_objectness: 0.0001 (0.0003)  loss_rpn_box_reg: 0.0003 (0.0005)  time: 0.7791  data: 0.0386  max mem: 7567\n# Epoch: [0]  [ 300/3815]  eta: 0:47:25  lr: 0.001508  loss: 0.0267 (0.0332)  loss_classifier: 0.0085 (0.0107)  loss_box_reg: 0.0179 (0.0217)  loss_objectness: 0.0001 (0.0003)  loss_rpn_box_reg: 0.0002 (0.0004)  time: 0.7831  data: 0.0374  max mem: 7580\n# Epoch: [0]  [ 400/3815]  eta: 0:46:00  lr: 0.002008  loss: 0.0254 (0.0325)  loss_classifier: 0.0078 (0.0104)  loss_box_reg: 0.0195 (0.0214)  loss_objectness: 0.0000 (0.0003)  loss_rpn_box_reg: 0.0003 (0.0004)  time: 0.8053  data: 0.0363  max mem: 8301\n# Epoch: [0]  [ 500/3815]  eta: 0:44:22  lr: 0.002507  loss: 0.0300 (0.0330)  loss_classifier: 0.0096 (0.0104)  loss_box_reg: 0.0196 (0.0219)  loss_objectness: 0.0001 (0.0003)  loss_rpn_box_reg: 0.0004 (0.0004)  time: 0.7881  data: 0.0366  max mem: 8301\n# Epoch: [0]  [ 600/3815]  eta: 0:42:48  lr: 0.003007  loss: 0.0299 (0.0331)  loss_classifier: 0.0096 (0.0104)  loss_box_reg: 0.0181 (0.0220)  loss_objectness: 0.0000 (0.0002)  loss_rpn_box_reg: 0.0003 (0.0004)  time: 0.7799  data: 0.0375  max mem: 8301\n# Epoch: [0]  [ 700/3815]  eta: 0:41:30  lr: 0.003506  loss: 0.0342 (0.0335)  loss_classifier: 0.0095 (0.0104)  loss_box_reg: 0.0233 (0.0224)  loss_objectness: 0.0001 (0.0002)  loss_rpn_box_reg: 0.0003 (0.0005)  time: 0.8029  data: 0.0393  max mem: 8301\n# Epoch: [0]  [ 800/3815]  eta: 0:40:12  lr: 0.004006  loss: 0.0271 (0.0338)  loss_classifier: 0.0078 (0.0104)  loss_box_reg: 0.0188 (0.0227)  loss_objectness: 0.0000 (0.0002)  loss_rpn_box_reg: 0.0003 (0.0005)  time: 0.8359  data: 0.0394  max mem: 8301\n# Epoch: [0]  [ 900/3815]  eta: 0:38:49  lr: 0.004505  loss: 0.0292 (0.0338)  loss_classifier: 0.0092 (0.0105)  loss_box_reg: 0.0195 (0.0227)  loss_objectness: 0.0001 (0.0002)  loss_rpn_box_reg: 0.0003 (0.0005)  time: 0.7757  data: 0.0408  max mem: 8303\n# Epoch: [0]  [1000/3815]  eta: 0:37:26  lr: 0.005000  loss: 0.0376 (0.0343)  loss_classifier: 0.0083 (0.0106)  loss_box_reg: 0.0244 (0.0230)  loss_objectness: 0.0001 (0.0003)  loss_rpn_box_reg: 0.0005 (0.0005)  time: 0.7923  data: 0.0363  max mem: 8303\n# Epoch: [0]  [1100/3815]  eta: 0:36:05  lr: 0.005000  loss: 0.0334 (0.0345)  loss_classifier: 0.0095 (0.0107)  loss_box_reg: 0.0208 (0.0231)  loss_objectness: 0.0001 (0.0003)  loss_rpn_box_reg: 0.0004 (0.0005)  time: 0.8237  data: 0.0382  max mem: 8303\n# Epoch: [0]  [1200/3815]  eta: 0:34:41  lr: 0.005000  loss: 0.0279 (0.0344)  loss_classifier: 0.0087 (0.0107)  loss_box_reg: 0.0190 (0.0230)  loss_objectness: 0.0000 (0.0003)  loss_rpn_box_reg: 0.0003 (0.0005)  time: 0.7455  data: 0.0416  max mem: 8303\n# Epoch: [0]  [1300/3815]  eta: 0:33:20  lr: 0.005000  loss: 0.0367 (0.0347)  loss_classifier: 0.0114 (0.0107)  loss_box_reg: 0.0242 (0.0232)  loss_objectness: 0.0001 (0.0003)  loss_rpn_box_reg: 0.0003 (0.0005)  time: 0.8035  data: 0.0369  max mem: 8303\n# Epoch: [0]  [1400/3815]  eta: 0:32:01  lr: 0.005000  loss: 0.0296 (0.0346)  loss_classifier: 0.0093 (0.0107)  loss_box_reg: 0.0213 (0.0231)  loss_objectness: 0.0001 (0.0003)  loss_rpn_box_reg: 0.0003 (0.0005)  time: 0.7964  data: 0.0384  max mem: 8303\n# Epoch: [0]  [1500/3815]  eta: 0:30:40  lr: 0.005000  loss: 0.0281 (0.0347)  loss_classifier: 0.0083 (0.0108)  loss_box_reg: 0.0200 (0.0232)  loss_objectness: 0.0001 (0.0003)  loss_rpn_box_reg: 0.0002 (0.0005)  time: 0.7836  data: 0.0388  max mem: 8303\n# Epoch: [0]  [1600/3815]  eta: 0:29:19  lr: 0.005000  loss: 0.0295 (0.0349)  loss_classifier: 0.0081 (0.0108)  loss_box_reg: 0.0187 (0.0233)  loss_objectness: 0.0001 (0.0003)  loss_rpn_box_reg: 0.0003 (0.0005)  time: 0.7345  data: 0.0391  max mem: 8303\n# Epoch: [0]  [1700/3815]  eta: 0:27:56  lr: 0.005000  loss: 0.0307 (0.0351)  loss_classifier: 0.0088 (0.0108)  loss_box_reg: 0.0206 (0.0235)  loss_objectness: 0.0001 (0.0003)  loss_rpn_box_reg: 0.0004 (0.0005)  time: 0.7649  data: 0.0376  max mem: 8303\n# Epoch: [0]  [1800/3815]  eta: 0:26:37  lr: 0.005000  loss: 0.0286 (0.0350)  loss_classifier: 0.0084 (0.0108)  loss_box_reg: 0.0196 (0.0235)  loss_objectness: 0.0001 (0.0003)  loss_rpn_box_reg: 0.0003 (0.0005)  time: 0.8076  data: 0.0350  max mem: 8303\n# Epoch: [0]  [1900/3815]  eta: 0:25:17  lr: 0.005000  loss: 0.0253 (0.0348)  loss_classifier: 0.0069 (0.0107)  loss_box_reg: 0.0174 (0.0234)  loss_objectness: 0.0000 (0.0003)  loss_rpn_box_reg: 0.0002 (0.0005)  time: 0.8044  data: 0.0344  max mem: 8303\n# Epoch: [0]  [2000/3815]  eta: 0:23:59  lr: 0.005000  loss: 0.0331 (0.0349)  loss_classifier: 0.0100 (0.0107)  loss_box_reg: 0.0217 (0.0234)  loss_objectness: 0.0001 (0.0003)  loss_rpn_box_reg: 0.0003 (0.0005)  time: 0.8342  data: 0.0346  max mem: 8303\n# Epoch: [0]  [2100/3815]  eta: 0:22:40  lr: 0.005000  loss: 0.0286 (0.0349)  loss_classifier: 0.0097 (0.0107)  loss_box_reg: 0.0184 (0.0234)  loss_objectness: 0.0001 (0.0003)  loss_rpn_box_reg: 0.0003 (0.0005)  time: 0.7971  data: 0.0340  max mem: 8303\n# Epoch: [0]  [2200/3815]  eta: 0:21:19  lr: 0.005000  loss: 0.0293 (0.0347)  loss_classifier: 0.0082 (0.0107)  loss_box_reg: 0.0200 (0.0233)  loss_objectness: 0.0001 (0.0003)  loss_rpn_box_reg: 0.0003 (0.0005)  time: 0.7738  data: 0.0382  max mem: 8303\n# Epoch: [0]  [2300/3815]  eta: 0:19:59  lr: 0.005000  loss: 0.0348 (0.0349)  loss_classifier: 0.0102 (0.0107)  loss_box_reg: 0.0233 (0.0234)  loss_objectness: 0.0001 (0.0003)  loss_rpn_box_reg: 0.0004 (0.0005)  time: 0.7840  data: 0.0353  max mem: 8303\n# Epoch: [0]  [2400/3815]  eta: 0:18:40  lr: 0.005000  loss: 0.0391 (0.0351)  loss_classifier: 0.0098 (0.0108)  loss_box_reg: 0.0279 (0.0235)  loss_objectness: 0.0001 (0.0003)  loss_rpn_box_reg: 0.0004 (0.0005)  time: 0.8004  data: 0.0377  max mem: 8303\n# Epoch: [0]  [2500/3815]  eta: 0:17:21  lr: 0.005000  loss: 0.0313 (0.0351)  loss_classifier: 0.0087 (0.0108)  loss_box_reg: 0.0213 (0.0235)  loss_objectness: 0.0002 (0.0003)  loss_rpn_box_reg: 0.0003 (0.0005)  time: 0.8043  data: 0.0367  max mem: 8303\n# Epoch: [0]  [2600/3815]  eta: 0:16:02  lr: 0.005000  loss: 0.0308 (0.0349)  loss_classifier: 0.0094 (0.0107)  loss_box_reg: 0.0202 (0.0234)  loss_objectness: 0.0001 (0.0003)  loss_rpn_box_reg: 0.0004 (0.0005)  time: 0.7700  data: 0.0386  max mem: 8303\n# Epoch: [0]  [2700/3815]  eta: 0:14:41  lr: 0.005000  loss: 0.0268 (0.0347)  loss_classifier: 0.0083 (0.0107)  loss_box_reg: 0.0174 (0.0233)  loss_objectness: 0.0001 (0.0003)  loss_rpn_box_reg: 0.0003 (0.0005)  time: 0.7783  data: 0.0363  max mem: 8303\n# Epoch: [0]  [2800/3815]  eta: 0:13:22  lr: 0.005000  loss: 0.0307 (0.0346)  loss_classifier: 0.0094 (0.0107)  loss_box_reg: 0.0208 (0.0232)  loss_objectness: 0.0001 (0.0003)  loss_rpn_box_reg: 0.0003 (0.0005)  time: 0.7832  data: 0.0346  max mem: 8303\n# Epoch: [0]  [2900/3815]  eta: 0:12:03  lr: 0.005000  loss: 0.0341 (0.0346)  loss_classifier: 0.0082 (0.0107)  loss_box_reg: 0.0227 (0.0232)  loss_objectness: 0.0001 (0.0003)  loss_rpn_box_reg: 0.0002 (0.0005)  time: 0.8156  data: 0.0383  max mem: 8303\n# Epoch: [0]  [3000/3815]  eta: 0:10:44  lr: 0.005000  loss: 0.0346 (0.0348)  loss_classifier: 0.0102 (0.0108)  loss_box_reg: 0.0240 (0.0233)  loss_objectness: 0.0001 (0.0003)  loss_rpn_box_reg: 0.0004 (0.0005)  time: 0.7929  data: 0.0357  max mem: 8303\n# Epoch: [0]  [3100/3815]  eta: 0:09:25  lr: 0.005000  loss: 0.0317 (0.0347)  loss_classifier: 0.0099 (0.0107)  loss_box_reg: 0.0203 (0.0232)  loss_objectness: 0.0002 (0.0003)  loss_rpn_box_reg: 0.0003 (0.0005)  time: 0.7600  data: 0.0382  max mem: 8303\n# Epoch: [0]  [3200/3815]  eta: 0:08:06  lr: 0.005000  loss: 0.0307 (0.0347)  loss_classifier: 0.0102 (0.0107)  loss_box_reg: 0.0202 (0.0232)  loss_objectness: 0.0001 (0.0003)  loss_rpn_box_reg: 0.0003 (0.0005)  time: 0.7697  data: 0.0360  max mem: 8303\n# Epoch: [0]  [3300/3815]  eta: 0:06:47  lr: 0.005000  loss: 0.0282 (0.0346)  loss_classifier: 0.0080 (0.0107)  loss_box_reg: 0.0190 (0.0232)  loss_objectness: 0.0000 (0.0003)  loss_rpn_box_reg: 0.0002 (0.0005)  time: 0.8271  data: 0.0373  max mem: 8303\n# Epoch: [0]  [3400/3815]  eta: 0:05:28  lr: 0.005000  loss: 0.0270 (0.0345)  loss_classifier: 0.0077 (0.0107)  loss_box_reg: 0.0194 (0.0231)  loss_objectness: 0.0001 (0.0003)  loss_rpn_box_reg: 0.0003 (0.0005)  time: 0.7703  data: 0.0366  max mem: 8303\n# Epoch: [0]  [3500/3815]  eta: 0:04:08  lr: 0.005000  loss: 0.0241 (0.0344)  loss_classifier: 0.0080 (0.0107)  loss_box_reg: 0.0172 (0.0230)  loss_objectness: 0.0001 (0.0003)  loss_rpn_box_reg: 0.0003 (0.0005)  time: 0.7804  data: 0.0375  max mem: 8303\n# Epoch: [0]  [3600/3815]  eta: 0:02:49  lr: 0.005000  loss: 0.0292 (0.0343)  loss_classifier: 0.0086 (0.0106)  loss_box_reg: 0.0200 (0.0230)  loss_objectness: 0.0001 (0.0003)  loss_rpn_box_reg: 0.0004 (0.0005)  time: 0.7968  data: 0.0349  max mem: 8303\n# Epoch: [0]  [3700/3815]  eta: 0:01:30  lr: 0.005000  loss: 0.0302 (0.0343)  loss_classifier: 0.0083 (0.0106)  loss_box_reg: 0.0197 (0.0229)  loss_objectness: 0.0001 (0.0003)  loss_rpn_box_reg: 0.0002 (0.0005)  time: 0.7514  data: 0.0389  max mem: 8303\n# Epoch: [0]  [3800/3815]  eta: 0:00:11  lr: 0.005000  loss: 0.0272 (0.0343)  loss_classifier: 0.0081 (0.0106)  loss_box_reg: 0.0192 (0.0229)  loss_objectness: 0.0001 (0.0003)  loss_rpn_box_reg: 0.0003 (0.0005)  time: 0.7898  data: 0.0372  max mem: 8303\n# Epoch: [0]  [3814/3815]  eta: 0:00:00  lr: 0.005000  loss: 0.0293 (0.0343)  loss_classifier: 0.0094 (0.0106)  loss_box_reg: 0.0208 (0.0229)  loss_objectness: 0.0001 (0.0003)  loss_rpn_box_reg: 0.0004 (0.0005)  time: 0.7795  data: 0.0337  max mem: 8303\n# Epoch: [0] Total time: 0:50:13 (0.7899 s / it)\n# creating index...\n# index created!\n# Test:  [ 0/50]  eta: 0:00:59  model_time: 0.2925 (0.2925)  evaluator_time: 0.0252 (0.0252)  time: 1.1811  data: 0.8524  max mem: 8303\n# Test:  [49/50]  eta: 0:00:00  model_time: 0.0684 (0.0997)  evaluator_time: 0.0067 (0.0075)  time: 0.1138  data: 0.0148  max mem: 8303\n# Test: Total time: 0:00:07 (0.1593 s / it)\n# Averaged stats: model_time: 0.0684 (0.0997)  evaluator_time: 0.0067 (0.0075)\n# Accumulating evaluation results...\n# DONE (t=0.02s).\n# IoU metric: bbox\n#  Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.872\n#  Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 1.000\n#  Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.978\n#  Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n#  Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n#  Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.872\n#  Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.860\n#  Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.892\n#  Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.892\n#  Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n#  Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n#  Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.892","metadata":{"jupyter":{"source_hidden":true}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Test thử khả năng phát hiện khuôn mặt của model bằng cách tạo bounding box trên ảnh","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nfrom torchvision.utils import draw_bounding_boxes, draw_segmentation_masks\n\nnum_classes = 2\n# train on the GPU or on the CPU, if a GPU is not available\ndevice = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n# get the model using our helper function\nmodel = get_model(num_classes)\n# move model to the right device\nmodel.to(device)\nmodel.load_state_dict(torch.load(\"/kaggle/input/modelweight/model_v2.pth\"))\n\nimage = read_image(\"/kaggle/input/face-public-test/public_test/102495577.jpg\")\neval_transform = get_transform(train=False)\n\nmodel.eval()\nwith torch.no_grad():\n    x = eval_transform(image)\n    # convert RGBA -> RGB and move to device\n    x = x[:3, ...].to(device)\n    predictions = model([x, ])\n    pred = predictions[0]\n\n\nimage = (255.0 * (image - image.min()) / (image.max() - image.min())).to(torch.uint8)\nimage = image[:3, ...]\npred_labels = [f\"face: {score:.3f}\" for label, score in zip(pred[\"labels\"], pred[\"scores\"])]\npred_boxes = pred[\"boxes\"]\nprint(pred_boxes[0].tolist())\noutput_image = draw_bounding_boxes(image, pred_boxes, pred_labels, colors=\"red\", font=\"/kaggle/input/boxesfont/Roboto-Bold.ttf\",font_size=20)\n\n\nplt.figure(figsize=(12, 12))\nplt.imshow(output_image.permute(1, 2, 0))","metadata":{"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-01-11T06:48:22.510736Z","iopub.execute_input":"2024-01-11T06:48:22.511143Z","iopub.status.idle":"2024-01-11T06:48:24.767457Z","shell.execute_reply.started":"2024-01-11T06:48:22.511111Z","shell.execute_reply":"2024-01-11T06:48:24.766525Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Chạy model trên tập test dataset","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nfrom torchvision.utils import draw_bounding_boxes, draw_segmentation_masks\n\nnum_classes = 2\n# train on the GPU or on the CPU, if a GPU is not available\ndevice = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n# get the model using our helper function\nmodel = get_model(num_classes)\n# model= nn.DataParallel(model)\n# move model to the right device\nmodel.to(device)\nmodel.load_state_dict(torch.load(\"/kaggle/input/modelweight/model_v2.pth\"))\n\nfilelist = os.listdir(\"/kaggle/input/face-public-test/public_test\")\n\nimg_dict = {\n    \"file_name\": [],\n    \"bbox\": []\n}\nfor filename in filelist:\n    image = read_image(f\"/kaggle/input/face-public-test/public_test/{filename}\")\n    eval_transform = get_transform(train=False)\n    \n    model.eval()\n    with torch.no_grad():\n        x = eval_transform(image)\n        # convert RGBA -> RGB and move to device\n        x = x[:3, ...].to(device)\n        predictions = model([x, ])\n        pred = predictions[0]\n\n    pred_boxes = pred[\"boxes\"]\n    for i in range(len(pred_boxes)):\n        img_dict[\"file_name\"].append(filename)\n        tmp = pred_boxes[i].tolist()\n        img_dict[\"bbox\"].append([int(tmp[0]), int(tmp[1]), int(abs(tmp[2] - tmp[0])), int(abs(tmp[3] - tmp[1]))])\n\ndf = pd.DataFrame(img_dict)\ndisplay(df)","metadata":{"execution":{"iopub.status.busy":"2024-01-11T07:13:10.489786Z","iopub.execute_input":"2024-01-11T07:13:10.490164Z","iopub.status.idle":"2024-01-11T07:17:00.863699Z","shell.execute_reply.started":"2024-01-11T07:13:10.49013Z","shell.execute_reply":"2024-01-11T07:17:00.862654Z"},"trusted":true},"execution_count":null,"outputs":[]}]}